@article{Tomasi1998,
	abstract = {Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image},
	author = {Tomasi, C. and Manduchi, R.},
	doi = {10.1109/ICCV.1998.710815},
	file = {:E$\backslash$:/PAPERS/Medeley/1998/Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)/Tomasi, Manduchi/Tomasi, Manduchi - 1998 - Bilateral filtering for gray and color images.pdf:pdf},
	isbn = {81-7319-221-9},
	issn = {1873622X},
	journal = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {839--846},
	pmid = {8038605},
	title = {{Bilateral filtering for gray and color images}},
	url = {http://ieeexplore.ieee.org/document/710815/},
	year = {1998}
}
@article{Paris2008,
	abstract = {The bilateral filter is a non-linear technique that can blur an image while respecting strong edges. Its ability to decompose an image into different scales without causing haloes after modification has made it ubiquitous in computational photography applications such as tone mapping, style transfer, relighting, and denoising. This text provides a graphical, intuitive introduction to bilateral filtering, a practical guide for efficient implementation and an overview of its numerous applications, as well as mathematical analysis.},
	author = {Paris, Sylvain and Kornprobst, Pierre and Tumblin, JackTumblin and Durand, Fredo},
	doi = {10.1561/0600000020},
	file = {:E$\backslash$:/PAPERS/Medeley/2008/Foundations and Trends{\textregistered} in Computer Graphics and Vision/Paris et al/Paris et al. - 2008 - Bilateral Filtering Theory and Applications.pdf:pdf},
	isbn = {1439817499},
	issn = {1572-2740},
	journal = {Foundations and Trends{\textregistered} in Computer Graphics and Vision},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {1},
	pages = {1--75},
	title = {{Bilateral Filtering: Theory and Applications}},
	url = {http://www.nowpublishers.com/article/Details/CGV-020},
	volume = {4},
	year = {2008}
}
@book{Gonzalez06DIP,
	address = {Upper Saddle River, NJ, USA},
	author = {Gonzalez, Rafael C and Woods, Richard E},
	isbn = {013168728X},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	publisher = {Prentice-Hall, Inc.},
	title = {{Digital Image Processing (3rd Edition)}},
	year = {2006}
}
@inproceedings{Motwani2004,
	abstract = {Removing noise from the original signal is still a challenging problem for researchers. There have been several published algorithms and each approach has its assumptions, advantages, and limitations. This paper presents a review of some significant work in the area of image denoising. After a brief introduction, some popular approaches are classified into different groups and an overview of various algorithms and analysis is provided. Insights and potential future trends in the area of denoising are also discussed.},
	author = {Motwani, M.C. and Gadiya, M.C. and Motwani, R.C. and {Harris Jr}, F.C.},
	booktitle = {Proceedings of GSPx},
	file = {:E$\backslash$:/PAPERS/Medeley/2013/Life Science Journal/Ahmadi et al/Ahmadi et al. - 2013 - Survey of image denoising techniques.pdf:pdf},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {27--30},
	title = {{Survey of image denoising techniques}},
	year = {2004}
}

@article{He2013,
	abstract = {In this paper, we propose a novel explicit image filter called guided filter. Derived from a local linear model, the guided filter computes the filtering output by considering the content of a guidance image, which can be the input image itself or another different image. The guided filter can be used as an edge-preserving smoothing operator like the popular bilateral filter [1], but it has better behaviors near edges. The guided filter is also a more generic concept beyond smoothing: It can transfer the structures of the guidance image to the filtering output, enabling new filtering applications like dehazing and guided feathering. Moreover, the guided filter naturally has a fast and nonapproximate linear time algorithm, regardless of the kernel size and the intensity range. Currently, it is one of the fastest edge-preserving filters. Experiments show that the guided filter is both effective and efficient in a great variety of computer vision and computer graphics applications, including edge-aware smoothing, detail enhancement, HDR compression, image matting/feathering, dehazing, joint upsampling, etc.},
	author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
	doi = {10.1109/TPAMI.2012.213},
	file = {:E$\backslash$:/PAPERS/Medeley/2013/Unknown/He, Sun, Tang/He, Sun, Tang - 2013 - Guided Image Filtering.pdf:pdf},
	isbn = {3642155480},
	issn = {01628828},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Bilateral filter,Edge-preserving filtering,Linear time filtering},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {6},
	pages = {1397--1409},
	pmid = {23599054},
	title = {{Guided image filtering}},
	volume = {35},
	year = {2013}
}

@article{fodor2003denoising,
	abstract = {Techniques based on thresholding of wavelet coefficients are gaining popularity for denoising data. The idea is to transform the data into the wavelet basis, where the "large" coefficients are mainly the signal, and the "smaller" ones represent the noise. By suitably modifying these coefficients, the noise can be removed from the data. We evaluate several 2-D denoising procedures using test images corrupted with additive Gaussian noise. We consider global, level-dependent, and subband-dependent implementations of these techniques. Our results, using the mean squared error as a measure of the quality of denoising, show that the SureShrink and the BayesShrink methods consistently outperform the other wavelet-based techniques. In contrast, we found that a combination of simple spatial filters lead to images that were grainier with smoother edges, though the error was smaller than in the wavelet-based methods.},
	author = {Fodor, Imola K and Kamath, Chandrika},
	file = {:E$\backslash$:/PAPERS/Medeley/Unknown/Unknown/Unknown/Unknown - Unknown - Denoising Through Wavelet Shrinkage An Empirical Study.pdf:pdf},
	journal = {Journal of Electronic Imaging},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {1},
	pages = {151--160},
	publisher = {International Society for Optics and Photonics},
	title = {{Denoising through wavelet shrinkage: an empirical study}},
	volume = {12},
	year = {2003}
}

@article{Knaus2013,
	abstract = {Image denoising methods have been implemented in both spatial and transform domains. Each domain has its advantages and shortcomings, which can be complemented by each other. State-of-the-art methods like block-matching 3D filtering (BM3D) therefore combine both domains. However, implementation of such methods is not trivial. We offer a hybrid method that is surprisingly easy to implement and yet rivals BM3D in quality.},
	author = {Knaus, Claude and Zwicker, Matthias},
	doi = {10.1109/ICIP.2013.6738091},
	file = {:E$\backslash$:/PAPERS/Medeley/Unknown/Unknown/Knaus, Zwicker/Knaus, Zwicker - Unknown - DUAL-DOMAIN IMAGE DENOISING Claude Knaus Matthias Zwicker.pdf:pdf},
	isbn = {9781479923410},
	issn = {1522-4880},
	journal = {IEEE International Conference on Image Processing, ICIP 2013 - Proceedings},
	keywords = {bilateral filter,image denoising,short-time Fourier transform,wavelet shrinkage},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {4},
	pages = {440--444},
	title = {{Dual-domain image denoising}},
	year = {2013}
}

@article{Dabov2008,
	abstract = {We propose an image restoration technique exploiting regularized inversion and the recent block-matching and 3D filtering (BM3D) denoising filter. The BM3D employs a non-local modeling of images by collecting similar image patches in 3D arrays. The so-called collaborative filtering applied on such a 3D array is realized by transformdomain shrinkage. In this work, we propose an extension of the BM3D filter for colored noise, which we use in a two-step deblurring algorithm to improve the regularization after inversion in discrete Fourier domain. The first step of the algorithm is a regularized inversion using BM3D with collaborative hard-thresholding and the seconds step is a regularized Wiener inversion using BM3D with collaborative Wiener filtering. The experimental results show that the proposed technique is competitive with and in most cases outperforms the current best image restoration methods in terms of improvement in signal-to-noise ratio.},
	author = {Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
	journal = {Proceedings of SPIE-IS{\&}T, Image Processing: Algorithms and Systems VI, San Jose, California, USA, 28 January 2008},
	keywords = {block-matching,collaborative filtering,deblurring,deconvolution,image restoration},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {213462},
	pages = {12},
	title = {{Image restoration by sparse 3D transform-domain collaborative filtering}},
	volume = {6812},
	year = {2008}
}

@article{Dabov2008_1,
	abstract = {We propose an image denoising method that exploits both non- local image modeling and locally adaptive anisotropic estimation. The method uses grouping of adaptive-shape neighborhoods whose surrounding square supersets have been found similar by a block- matching procedure. The data deÞned on these grouped neighbor- hoods is stacked together, resulting in 3-D data structures which are generalized cylinders with adaptive-shape cross sections. Because of the similarity, which follows from the matching, and because of the adaptive selection of the shape of the neighborhoods, these 3-D groups are characterized by a high correlation along all the three di- mensions. We apply a 3-D decorrelating transform, computed as a separable composition of the Shape-Adaptive DCT (SA-DCT) and a 1-D orthonormal transform, and subsequently attenuate the noise by spectrum shrinkage with hard-thresholding or Wiener Þltering. Inversion of the 3-D transform produces individual estimates for all grouped neighborhoods. These estimates are returned to their original locations and aggregated with other estimates coming from different groups. Overall, thismethod generalizes two existing Þlters: the BM3D Þlter,which uses grouping of Þxed-size square blocks, and the Poin- wise SA-DCT Þlter, which exploits shrinkage on adaptive-shape supports. We show that the developedmethod inherits the strengths of both Þlters, resulting in a very effective and {\ss}exible tool for im- age denoising.},
	author = {Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen and Box, P O},
	file = {:E$\backslash$:/PAPERS/Medeley/Unknown/Unknown/Dabov et al/Dabov et al. - Unknown - a Nonlocal and Shape-Adaptive Transform-Domain Collaborative Filtering.pdf:pdf},
	journal = {Proc. Int. Workshop on Local and Non-Local Approx. in Image Process.},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {x},
	pages = {9},
	title = {{a Nonlocal and Shape-Adaptive Transform-Domain Collaborative Filtering}},
	year = {2008}
}

@article{Dabov2009,
	abstract = {We propose an image denoising method that ex- ploits nonlocal image modeling, principal component analysis (PCA), and local shape-adaptive anisotropic estimation. The nonlocal modeling is exploited by grouping similar image patches in 3-D groups. The denoising is performed by shrinkage of the spectrum of a 3-D transform applied on such groups. The effectiveness of the shrinkage depends on the ability of the transform to sparsely represent the true-image data, thus separating it from the noise.We propose to improve the sparsity in two aspects. First, we employ image patches (neighborhoods) which can have data-adaptive shape. Second, we propose PCA on these adaptive-shape neighborhoods as part of the employed 3-D transform. The PCA bases are obtained by eigenvalue decompo- sition of empirical second-moment matrices that are estimated from groups of similar adaptive-shape neighborhoods. We show that the proposed method is competitive and outperforms some of the current best denoising methods, especially in preserving image details and introducing very few artifacts.},
	author = {Dabov, Kostadin and Foi, Ro and Katkovnik, Vladimir and Egiazarian, Karen},
	doi = {10.1117/12.643267},
	file = {:E$\backslash$:/PAPERS/Medeley/Unknown/Unknown/Dabov et al/Dabov et al. - Unknown - BM3D Image Denoising with Shape-Adaptive Principal Component Analysis.pdf:pdf},
	isbn = {0819461040},
	issn = {0277786X},
	journal = {Proc. Workshop on Signal Processing with Adaptive Sparse Structured Representations},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {6},
	title = {{BM3D image denoising with shape-adaptive principal component analysis}},
	year = {2009}
}

@article{Lebrun2012,
	abstract = {BM3D is a recent denoising method based on the fact that an image has a locally sparse representation in transform domain. This sparsity is enhanced by grouping similar 2D image patches into 3D groups. In this paper we propose an open-source implementation of the method. We discuss the choice of all parameter methods and confirm their actual optimality. The description of the method is rewritten with a new notation. We hope this new notation is more transparent than in the original paper. A final index gives nonetheless the correspondence between the new notation and the original notation.},
	author = {Lebrun, Marc},
	doi = {10.5201/ipol.2012.l-bm3d},
	file = {:E$\backslash$:/PAPERS/Medeley/2012/Image Processing On Line/Lebrun/Lebrun - 2012 - An Analysis and Implementation of the BM3D Image Denoising Method.pdf:pdf},
	isbn = {2105-1232},
	issn = {2105-1232},
	journal = {Image Processing On Line},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {May},
	pages = {175--213},
	title = {{An Analysis and Implementation of the BM3D Image Denoising Method}},
	url = {http://www.ipol.im/pub/art/2012/l-bm3d/?utm{\_}source=doi},
	volume = {2},
	year = {2012}
}

@article{Allen1977,
	abstract = {A theory of short term spectral analysis, synthesis, and modification is presented with an attempt at pointing out certain practical and theoretical questions. The methods discussed here are useful in designing filter banks when the filter bank outputs are to be used for synthesis after multiplicative modifications are made to the spectrum.},
	author = {Allen, J},
	doi = {10.1109/TASSP.1977.1162950},
	file = {:E$\backslash$:/PAPERS/Medeley/1977/Unknown/Allen/Allen - 1977 - Short term spectral analysis, synthesis, and modification by discrete fourier transform.pdf:pdf},
	issn = {0096-3518},
	journal = {Acoustics, Speech and Signal Processing, IEEE Transactions on},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {3},
	pages = {235--238},
	title = {{Short term spectral analysis, synthesis, and modification by discrete Fourier transform}},
	volume = {25},
	year = {1977}
}

@article{Donoho1995,
	abstract = {Much recent effort has sought asymptotically minimax methods for recovering infinite dimensional objects--curves, densities, spectral densities, images--from noisy data. A now rich and complex body of work develops nearly or exactly minimax estimators for an array of interesting problems. Unfortunately, the results have rarely moved into practice, for a variety of reasons--among them being similarity to known methods, computational intractability and lack of spatial adaptivity. We discuss a arise from iterated mappings of the centre of the interval to which the map is applied. Particular attention is paid to the shape of an invariant distribution in the tails or in the neighbourhood of a pole of its density. A new technique is developed for this application. It enables us to combine `parametric' information, available from the structure of the map, with `nonparametric' information obtainable from numerical experiments.},
	author = {Donoho, David L. and Johnstone, Iain M. and Kerkyacharian, Gerard and Picard, Dominique},
	doi = {10.2307/2345967},
	file = {:E$\backslash$:/PAPERS/Medeley/Unknown/Unknown/Donoho et al/Donoho et al. - Unknown - Wavelet Shrinkage Asymptopia 1 Classical Minimaxity 2 Post-Classical Minimaxity.pdf:pdf},
	isbn = {0035-9246},
	issn = {0035-9246},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	keywords = {Adaptive Estimation,Besov Spaces,Density Estimation,Minimax Estimation,Nonparametric Regression,Optimal Recoery,Spatial Adaptation,Wavelet Orthonormal bases},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {2},
	pages = {301--369},
	title = {{Wavelet Shrinkage: Asymptopia?}},
	url = {http://statweb.stanford.edu/{~}imj/WEBLIST/1995/asymp.pdf},
	volume = {57},
	year = {1995}
}

@article{Zong1996,
	abstract = {This p a p e r presents an approach which addresses both de-noising and contrast enhancement. In a multiscale$\backslash$nWavelet analysis frarnework, We take advantage of both soft thresholding and hard thresholding Wavelet shrinkage techniques to reduce noise. In addition, We carry out nonlinear processing to enhance contrast Within structures and along boundaries. Feature restoration and enhancernent are accornplished by rnodifying the gain of a signal's variational energy.$\backslash$nThe rnultiscale discrete dyadic Wavelet transforrn adapted in this paper is treated as a process for the diffusion of variational energy frorn a signal stored as the power (scaled variational energy) of Wavelet coeflicients. We show that a discrete dyadic Wavelet transforrn has the capability to separate feature variational energy frorn noise variational energy. De-Noising and feature enhancernent are achieved by sirnultaneously lowering noise variational energy and raising feature variational energy in the transforrn dornain. We present Inethods for achieving this objective, including$\backslash$nregulated soft thresholding and adaptive nonlinear processing combined with hard thresholding.$\backslash$nWe have applied this algorithrn to synthetic and real signals as well as images Vvith additive Gaussian Vvhite noise. Experiniental results show that de—noised as well as enhanced signals and images are free frorn artifacts. Sarnple$\backslash$nanalysis and experiniental results are presented.},
	author = {Zong, Xuli},
	doi = {10.1117/12.236028},
	file = {:E$\backslash$:/PAPERS/Medeley/1996/Proceedings of SPIE/Zong/Zong - 1996 - De-noising and contrast enhancement via wavelet shrinkage and nonlinear adaptive gain.pdf:pdf},
	isbn = {081942143X},
	issn = {0277786X},
	journal = {Proceedings of SPIE},
	keywords = {de-noising,feature enhancement,nonlinear processing,wavelet shrinkage,wavelet transform},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {566--574},
	title = {{De-noising and contrast enhancement via wavelet shrinkage and nonlinear adaptive gain}},
	url = {http://link.aip.org/link/?PSI/2762/566/1{\&}Agg=doi},
	volume = {2762},
	year = {1996}
}

@article{Taswell2000,
	abstract = {Wavelet shrinkage denoising provides a novel method of reducing$\backslash$nnoise in signals. The author demonstrates 1D and 2D examples, tests the$\backslash$nperformance of various ideal and practical Fourier- and wavelet-based$\backslash$ndenoising procedures, and makes recommendations for practitioners. It is$\backslash$nis concluded that it is unlikely that one particular wavelet shrinkage$\backslash$ndenoising procedure will be suitable, no less optimal, for all practical$\backslash$nproblems. However, it is likely that there will be many practical$\backslash$nproblems, for which after appropriate experimentation, wavelet-based$\backslash$ndenoising with either hard or soft thresholding proves to be the most$\backslash$neffective procedure. Using wavelet-based denoising of the$\backslash$nlog-periodogram to estimate the power spectrum might prove to be one$\backslash$nsuch important application with great promise for further development$\backslash$n},
	author = {Taswell, Carl},
	doi = {10.1109/5992.841791},
	file = {:E$\backslash$:/PAPERS/Medeley/1998/Unknown/Taswell/Taswell - 1998 - The What , How , and Why of Wavelet Shrinkage Denoising A Simple Explanation and a 1-D Example.pdf:pdf},
	isbn = {doi:10.1109/5992.841791},
	issn = {15219615},
	journal = {Computing in Science and Engineering},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {3},
	pages = {12--19},
	title = {{The What How, and Why of Wavelet Shrinkage Denoising}},
	volume = {2},
	year = {2000}
}

@inproceedings{Pierazzo2014,
	abstract = {The current state-of-the-art non-local algorithms for image denoising have the tendency to remove many low contrast details. Frequency-based algorithms keep these details, but on the other hand many artifacts are introduced. Recently, the Dual Domain Image Denoising (DDID) method has been proposed to address this issue. While beating the state-of-the-art, this algorithm still causes strong frequency domain artifacts. This paper reviews DDID under a different light, allowing to understand their origin. The analysis leads to the development of NLDD, a new denoising algorithm that outperforms DDID, BM3D and other state-of-the-art algorithms. NLDD is also three times faster than DDID and easily parallelizable.},
	author = {Pierazzo, N. and Lebrun, M. and Rais, M. E. and Morel, J. M. and Facciolo, G.},
	booktitle = {2014 IEEE International Conference on Image Processing, ICIP 2014},
	doi = {10.1109/ICIP.2014.7025163},
	file = {:E$\backslash$:/PAPERS/Medeley/2014/Unknown/Pierazzo et al/Pierazzo et al. - 2014 - NON-LOCAL DUAL IMAGE DENOISING.pdf:pdf},
	isbn = {9781479957514},
	keywords = {Dual Denoising,Fourier shrinkage,Image denoising,Non-Local Bayes,Patch-Based methods},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {813--817},
	title = {{Non-local dual image denoising}},
	year = {2014}
}

@article{Rudin1992,
	abstract = {A constrained optimization type of numerical algorithm for removing noise from images is presented. The total variation of the image is minimized subject to constraints involving the statistics of the noise. The constraints are imposed using Lanrange multipliers. The solution is obtained using the gradient-projection method. This amounts to solving a time dependent partial differential equation on a manifold determined by the constraints. As t → ∞ the solution converges to a steady state which is the denoised image. The numerical algorithm is simple and relatively fast. The results appear to be state-of-the-art for very noisy images. The method is noninvasive, yielding sharp edges in the image. The technique could be interpreted as a first step of moving each level set of the image normal to itself with velocity equal to the curvature of the level set divided by the magnitude of the gradient of the image, and a second step which projects the image back onto the constraint set.},
	author = {Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
	doi = {http://dx.doi.org/10.1016/0167-2789(92)90242-F},
	file = {:E$\backslash$:/PAPERS/Medeley/1992/Unknown/Monica/Monica - 1992 - Nonlinear total variation based noise removal algorithms.pdf:pdf},
	isbn = {0167-2789},
	issn = {0167-2789},
	journal = {Phys. D},
	keywords = {total variation},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	number = {1-4},
	pages = {259--268},
	title = {{Nonlinear total variation based noise removal algorithms}},
	volume = {60},
	year = {1992}
}
@article{Chambolle2010,
	abstract = {These notes address various theoretical and practical topics related to Total Variation-based image reconstruction. They focuse first on some theoretical results on functions which minimize the total variation, and in a second part, describe a few standard and less standard algorithms to minimize the total variation in a finite-differences setting, with a series of applications from simple denoising to stereo, or deconvolution issues, and even more exotic uses like the minimization of minimal partition problems.},
	author = {Chambolle, Antonin and Caselles, Vicent and Cremers, Daniel and Novaga, Matteo and Pock, Thomas},
	doi = {10.1515/9783110226157.263},
	file = {:E$\backslash$:/PAPERS/Medeley/2009/Unknown/Chambolle et al/Chambolle et al. - 2009 - An introduction to Total Variation for Image Analysis Thomas Pock To cite this version An introduction to Tot.pdf:pdf},
	isbn = {9783110226157},
	journal = {Theoretical foundations and numerical methods for sparse recovery},
	keywords = {calculus of variations},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {263--340},
	title = {{An Introduction to Total Variation for Image Analysis}},
	volume = {9},
	year = {2010}
}
@article{Duran2013,
	abstract = {Denoising is the problem of removing the inherent noise from an image. The standard noise model is additive white Gaussian noise, where the observed image f is related to the underlying true image u by the degradation model f = u + $\eta$, and $\eta$ is supposed to be at each pixel independently and identically distributed as a zero-mean Gaussian random variable. Since this is an ill-posed problem, Rudin, Osher and Fatemi introduced the total variation as a regularizing term. It has proved to be quite efficient for regularizing images without smoothing the boundaries of the objects. This paper focuses on the simple description of the theory and on the implementation of Chambolle's projection algorithm for minimizing the total variation of a grayscale image. Furthermore, we adapt the algorithm to the vectorial total variation for color images. The implementation is described in detail and its parameters are analyzed and varied to come up with a reliable implementation.},
	author = {Duran, Joan and Coll, Bartomeu and Sbert, Catalina},
	doi = {10.5201/ipol.2013.61},
	file = {:E$\backslash$:/PAPERS/Medeley/2013/Image Processing On Line/Duran, Coll, Sbert/Duran, Coll, Sbert - 2013 - Chambolle's Projection Algorithm for Total Variation Denoising.pdf:pdf},
	issn = {2105-1232},
	journal = {Image Processing On Line},
	keywords = {denoising,image restoration,total variation},
	mendeley-groups = {PatternRecognitionLab/DIP/Survey Denoise},
	pages = {311--331},
	title = {{Chambolle's Projection Algorithm for Total Variation Denoising}},
	volume = {2013},
	year = {2013}
}

@ONLINE{Znah2013,
	author = {Alexander Mordvintsev},
	title = {ROF and TV-L1 denoising with Primal-Dual algorithm},
	url = {https://github.com/znah/notebooks/blob/master/TV\_denoise.ipynb},
	year = {2013}
}